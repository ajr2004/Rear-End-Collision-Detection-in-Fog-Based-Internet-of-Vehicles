{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WBg6_xpxyjKx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Bidirectional, LSTM, SimpleRNN\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "m1N911BF9TJU"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('..//dataset//final_dataset_compressed.csv')  # Replace with your dataset path\n",
        "\n",
        "# Separating features and target\n",
        "X = df[['Number of Lanes', 'Status of driver', 'Nature of environment', 'Velocity of vehicle', 'Distance between vehicles', 'Breaking capability']]\n",
        "y = df['Collussion']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# X_scaled = X\n",
        "\n",
        "# Reshape input to be 3D [samples, timesteps, features] for LSTM\n",
        "X_scaled = np.reshape(X_scaled, (X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq7xpL4V9cKQ",
        "outputId": "4c0dfa55-3f2e-4a52-fefe-5eab63dc38ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(320000, 1, 6) (320000,) (400000, 1, 6)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, y_train.shape,X_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "idsdruGv9d_t"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Input\n",
        "def build_optimized_rnn_bi_lstm():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Deep RNN layers\n",
        "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(SimpleRNN(units=100, return_sequences=True,kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(SimpleRNN(units=100, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Bidirectional LSTM layers\n",
        "    model.add(Bidirectional(LSTM(units=100, return_sequences=True, kernel_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Bidirectional(LSTM(units=100, return_sequences=True, kernel_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Bidirectional(LSTM(units=100, kernel_regularizer=l2(0.01))))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model with Adam optimizer (adjust learning rate)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['mse', 'mae'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLV3y0Et9jAk",
        "outputId": "70a345c5-2f28-4e79-b4bc-6e8b4f768d10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - loss: 2.6416 - mae: 0.0659 - mse: 0.0376 - val_loss: 0.0538 - val_mae: 0.0254 - val_mse: 0.0130\n",
            "Epoch 2/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step - loss: 0.0852 - mae: 0.0412 - mse: 0.0212 - val_loss: 0.0686 - val_mae: 0.0260 - val_mse: 0.0149\n",
            "Epoch 3/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step - loss: 0.0770 - mae: 0.0369 - mse: 0.0187 - val_loss: 0.0557 - val_mae: 0.0266 - val_mse: 0.0138\n",
            "Epoch 4/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step - loss: 0.0752 - mae: 0.0361 - mse: 0.0183 - val_loss: 0.0658 - val_mae: 0.0263 - val_mse: 0.0156\n",
            "Epoch 5/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7ms/step - loss: 0.0734 - mae: 0.0350 - mse: 0.0177 - val_loss: 0.0620 - val_mae: 0.0297 - val_mse: 0.0158\n",
            "Epoch 6/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7ms/step - loss: 0.0740 - mae: 0.0359 - mse: 0.0183 - val_loss: 0.0822 - val_mae: 0.0296 - val_mse: 0.0191\n",
            "Epoch 7/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7ms/step - loss: 0.0709 - mae: 0.0341 - mse: 0.0174 - val_loss: 0.0768 - val_mae: 0.0317 - val_mse: 0.0185\n",
            "Epoch 8/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7ms/step - loss: 0.0744 - mae: 0.0361 - mse: 0.0183 - val_loss: 0.0557 - val_mae: 0.0253 - val_mse: 0.0137\n",
            "Epoch 9/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7ms/step - loss: 0.0726 - mae: 0.0352 - mse: 0.0179 - val_loss: 0.0776 - val_mae: 0.0373 - val_mse: 0.0199\n",
            "Epoch 10/10\n",
            "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7ms/step - loss: 0.0716 - mae: 0.0347 - mse: 0.0176 - val_loss: 0.0627 - val_mae: 0.0272 - val_mse: 0.0161\n"
          ]
        }
      ],
      "source": [
        "optimized_model = build_optimized_rnn_bi_lstm()\n",
        "\n",
        "# Train the model\n",
        "optimized_history = optimized_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8dEJxbNb9l5b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set numpy to display full float numbers\n",
        "np.set_printoptions(suppress=True, precision=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM0OpBvi9n2K",
        "outputId": "b1533b7f-b008-4791-b10c-b802abd1fcbc"
      },
      "outputs": [],
      "source": [
        "# # Evaluate the model\n",
        "# loss, accuracy =optimized_model.evaluate(X_test, y_test, verbose=1)\n",
        "# print(f'Test Accuracy: {accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDo1JfyI9pjo",
        "outputId": "c92be23f-da3e-45bd-d706-51c70958253f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "Mean Squared Error (MSE): 0.0162941943854094\n",
            "Root Mean Squared Error (RMSE): 0.1276487147816591\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions\n",
        "y_pred = optimized_model.predict(X_test)\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error (MSE): {mse:.16f}')\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.16f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "zhfBQuXz9r0p",
        "outputId": "5bbf9441-4a42-456f-f825-70f32f281f14"
      },
      "outputs": [],
      "source": [
        "# #visualizing the loss and accuracy\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.figure(figsize=(10,5))\n",
        "# plt.subplot(1,2,1)\n",
        "# plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "# plt.title('Model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train','validation'],loc='upper left')\n",
        "\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('Model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train','validation'],loc='upper left')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0Fxr-id9ttP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
