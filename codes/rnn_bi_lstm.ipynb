{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,Bidirectional, LSTM, SimpleRNN\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('..//dataset//final_dataset_compressed.csv')  # Replace with your dataset path\n",
    "\n",
    "# Separating features and target\n",
    "X = df[['Number of Lanes', 'Status of driver', 'Nature of environment', 'Velocity of vehicle', 'Distance between vehicles', 'Breaking capability']]\n",
    "y = df['Collussion']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X_scaled = X\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features] for LSTM\n",
    "X_scaled = np.reshape(X_scaled, (X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000, 1, 6) (320000,) (400000, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape,X_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Conv1D, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "def build_deep_rnn_bi_lstm():\n",
    "      model = Sequential()\n",
    "\n",
    "      # Deep RNN layers\n",
    "      model.add(SimpleRNN(units=50, return_sequences=True,\n",
    "                           input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                           kernel_regularizer=l2(0.01)))\n",
    "      model.add(BatchNormalization())\n",
    "      model.add(Dropout(0.3))\n",
    "      model.add(SimpleRNN(units=50, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
    "      model.add(BatchNormalization())\n",
    "      model.add(Dropout(0.3))\n",
    "\n",
    "      # Bidirectional LSTM layers\n",
    "      model.add(Bidirectional(LSTM(units=50, return_sequences=True, kernel_regularizer=l2(0.01))))\n",
    "      model.add(BatchNormalization())\n",
    "      model.add(Dropout(0.3))\n",
    "      model.add(Bidirectional(LSTM(units=50, return_sequences=True, kernel_regularizer=l2(0.01))))\n",
    "      model.add(BatchNormalization())\n",
    "      model.add(Dropout(0.3))\n",
    "      model.add(Bidirectional(LSTM(units=50, kernel_regularizer=l2(0.01))))\n",
    "      model.add(BatchNormalization())\n",
    "      model.add(Dropout(0.3))\n",
    "\n",
    "      # Output layer\n",
    "      model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "      # Compile the model with Adam optimizer (adjust learning rate)\n",
    "      model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['mse', 'mae'])\n",
    "\n",
    "      return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\codes\\engineering_codes\\research\\conda_env_for_project\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 15ms/step - loss: 1.8455 - mae: 0.0925 - mse: 0.0515 - val_loss: 0.0546 - val_mae: 0.0278 - val_mse: 0.0140\n",
      "Epoch 2/5\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - loss: 0.0759 - mae: 0.0389 - mse: 0.0197 - val_loss: 0.0688 - val_mae: 0.0442 - val_mse: 0.0162\n",
      "Epoch 3/5\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9ms/step - loss: 0.0728 - mae: 0.0377 - mse: 0.0190 - val_loss: 0.0558 - val_mae: 0.0285 - val_mse: 0.0153\n",
      "Epoch 4/5\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 10ms/step - loss: 0.0715 - mae: 0.0370 - mse: 0.0188 - val_loss: 0.0824 - val_mae: 0.0313 - val_mse: 0.0214\n",
      "Epoch 5/5\n",
      "\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9ms/step - loss: 0.0692 - mae: 0.0357 - mse: 0.0180 - val_loss: 0.0534 - val_mae: 0.0232 - val_mse: 0.0138\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the model\n",
    "model = build_deep_rnn_bi_lstm()\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=5, \n",
    "    batch_size=64, \n",
    "    validation_split=0.2, \n",
    "    verbose=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set numpy to display full float numbers\n",
    "np.set_printoptions(suppress=True, precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "# results = model.evaluate(X_test, y_test, verbose=1)\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step\n",
      "Mean Squared Error (MSE): 0.0138694429770112\n",
      "Root Mean Squared Error (RMSE): 0.1177685992827086\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error (MSE): {mse:.16f}')\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.16f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #visualizing the loss and accuracy\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train','validation'],loc='upper left')\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train','validation'],loc='upper left')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_for_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
